{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HplT2-F4MnaNx0emmL0C4PGB5741wLHq",
      "authorship_tag": "ABX9TyNwXcayKaqmIx4er1htaH/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhd786/Pointnet_Pytorch/blob/master/pointnet_modelnet10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgMbAjOWTFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsTOO64iWkVU",
        "colab_type": "code",
        "outputId": "0543a413-881e-4a38-e897-60828e744abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install path.py;\n",
        "from path import Path\n",
        "%cd drive/My\\ Drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting path.py\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/0d/4caee829b04e3113b7069fa52063bce5c78e374e05850aa893549e917a1a/path.py-12.4.0-py3-none-any.whl\n",
            "Collecting path<13.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/24/5827e075036b5bb6b538f71bf39574d4a8024c5df51206cb9d6739e24d94/path-13.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from path<13.2->path.py) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.5; python_version < \"3.8\"->path<13.2->path.py) (3.1.0)\n",
            "Installing collected packages: path, path.py\n",
            "Successfully installed path-13.1.0 path.py-12.4.0\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEJ_w2yUW33F",
        "colab_type": "code",
        "outputId": "973c4fc2-c2a6-41b5-c8d1-5e8cd50fde22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 06:55:24--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.61\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.61|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473402300 (451M) [application/zip]\n",
            "Saving to: ‘ModelNet10.zip’\n",
            "\n",
            "ModelNet10.zip      100%[===================>] 451.47M  36.0MB/s    in 14s     \n",
            "\n",
            "2020-05-24 06:55:38 (33.2 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TxRozoXD_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ModelNet10.zip;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6LZZECTXShI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path=Path(\"ModelNet10\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v28z3vQwbFH1",
        "colab_type": "code",
        "outputId": "a517ed3c-3729-4e2e-a0f1-683cc833f020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)};\n",
        "print(classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bathtub': 0, 'bed': 1, 'chair': 2, 'desk': 3, 'dresser': 4, 'monitor': 5, 'night_stand': 6, 'sofa': 7, 'table': 8, 'toilet': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdTl2GGabM69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_off(file):\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "    return verts, faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OKpO3lIbuCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path/\"bathtub/train/bathtub_0001.off\", 'r') as f:\n",
        "  verts1, faces1 = read_off(f)\n",
        "i,j,k = np.array(faces1).T\n",
        "x,y,z = np.array(verts1).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ffgEi3b_4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_rotate(data):\n",
        "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
        "    frames=[]\n",
        "\n",
        "    def rotate_z(x, y, z, theta):\n",
        "        w = x+1j*y\n",
        "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
        "\n",
        "    for t in np.arange(0, 10.26, 0.1):\n",
        "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
        "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
        "    fig = go.Figure(data=data,\n",
        "                    layout=go.Layout(\n",
        "                        updatemenus=[dict(type='buttons',\n",
        "                                    showactive=False,\n",
        "                                    y=1,\n",
        "                                    x=0.8,\n",
        "                                    xanchor='left',\n",
        "                                    yanchor='bottom',\n",
        "                                    pad=dict(t=45, r=10),\n",
        "                                    buttons=[dict(label='Play',\n",
        "                                                    method='animate',\n",
        "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
        "                                                                    transition=dict(duration=0),\n",
        "                                                                    fromcurrent=True,\n",
        "                                                                    mode='immediate'\n",
        "                                                                    )]\n",
        "                                                    )\n",
        "                                            ]\n",
        "                                    )\n",
        "                                ]\n",
        "                    ),\n",
        "                    frames=frames\n",
        "            )\n",
        "\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PleLwnwodI0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IikoYLZnd7cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pcshow(xs,ys,zs):\n",
        "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
        "                                   mode='markers')]\n",
        "    fig = visualize_rotate(data)\n",
        "    fig.update_traces(marker=dict(size=1,\n",
        "                      line=dict(width=1,\n",
        "                      color='DarkSlateGrey')),\n",
        "                      selector=dict(mode='markers'))\n",
        "    fig.show()\n",
        "\n",
        "#pcshow(x,y,z)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8QbSUFqC4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def area(p1,p2,p3):\n",
        "   side_a = np.linalg.norm(p1 - p2)\n",
        "   side_b = np.linalg.norm(p2 - p3)\n",
        "   side_c = np.linalg.norm(p3 - p1)\n",
        "   s = 0.5 * ( side_a + side_b + side_c)\n",
        "   return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3NTvW8zrmgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_sample(verts,faces,n_faces):\n",
        "  areas = np.zeros((len(faces)))\n",
        "  verts = np.array(verts)\n",
        "  for i in range(len(faces)):\n",
        "    areas[i]=area(verts[faces[i][0]],verts[faces[i][1]],verts[faces[i][2]])\n",
        "\n",
        "  sampled_faces = (random.choices(faces, weights=areas,cum_weights=None,k=n_faces))\n",
        "  return sampled_faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz6U6MGueG2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def point_sample(data,n_points):\n",
        "  verts, faces = read_off(data)\n",
        "  sampled_faces=face_sample(verts,faces,n_points)\n",
        "  sampled_faces=np.array(sampled_faces)\n",
        "  verts = np.array(verts)\n",
        "  sampled_points=np.zeros((n_points,3))\n",
        "  for i in range(n_points):\n",
        "    s, t = sorted([random.random(), random.random()])\n",
        "    f = lambda j: s *verts[sampled_faces[i][0]][j]  + (t-s)*verts[sampled_faces[i][1]][j] + (1-t)*verts[sampled_faces[i][2]][j]\n",
        "    sampled_points[i][0]=f(0)\n",
        "    sampled_points[i][1]=f(1)\n",
        "    sampled_points[i][2]=f(2)\n",
        "\n",
        "  return sampled_points\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD4GtKEp1Y0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"ModelNet10/bathtub/train/bathtub_0001.off\", 'r') as f:\n",
        "  sample=point_sample(f,1024)\n",
        "\n",
        "x,y,z=np.array(sample).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvYhfu04Bg68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pcshow(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guhX56kdDeuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalise(sampled_points):\n",
        "  x,y,z=np.array(sampled_points).T\n",
        "  x=x-np.mean(x)\n",
        "  y=y-np.mean(y)\n",
        "  z=z-np.mean(z)\n",
        "  x1=x/np.max((x**2+y**2+z**2)**0.5)\n",
        "  y1=y/np.max((x**2+y**2+z**2)**0.5)\n",
        "  z1=z/np.max((x**2+y**2+z**2)**0.5)\n",
        "\n",
        "  return np.array([x1,y1,z1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5xkoexXFtL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y,z=normalise(sample)\n",
        "pcshow(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6dVPwIMF2hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate(normalised_points):\n",
        "   x,y,z=normalised_points\n",
        "   theta = random.random() * 2. * math.pi\n",
        "   rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),0],[ math.sin(theta),math.cos(theta),0],[0, 0,1]])\n",
        "   arr= np.array([x,y,z])\n",
        "   rot_pointcloud = rot_matrix.dot(arr)\n",
        "  # print(np.shape(rot_pointcloud[0]))\n",
        "   return  rot_pointcloud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lejbMugqIb9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y,z=rotate(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj7VsztGIjx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pcshow(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlsaENuVI81P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_noise(rot_cloud):\n",
        "  x,y,z=rot_cloud\n",
        "  noisex = np.random.normal(0, 0.02, (1024,))\n",
        "  noisey = np.random.normal(0, 0.02, (1024,))\n",
        "  noisez = np.random.normal(0, 0.02, (1024,))  \n",
        "  x=x+noisex\n",
        "  y=y+noisey\n",
        "  z=z+noisez\n",
        "  return np.array([x,y,z])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8EGt5y9Kmfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y,z=add_noise(x,y,z)\n",
        "pcshow(x,y,z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuqvKzrsLV5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_creator(root,n_points,folder):\n",
        "  folders = [dir for dir in sorted(os.listdir(root)) if os.path.isdir(root/dir)]\n",
        "  classes = {folder: i for i, folder in enumerate(folders)}\n",
        "  files = []\n",
        "  cloud=[]\n",
        "  for category in classes.keys():\n",
        "            new_dir = root/Path(category)/folder\n",
        "            for file in os.listdir(new_dir):\n",
        "                if file.endswith('.off'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    files.append(sample)\n",
        "  \n",
        "  for i,_ in enumerate(files):\n",
        "    pcd_path = files[i]['pcd_path']\n",
        "    category = files[i]['category']\n",
        "    with open(pcd_path, 'r') as f:\n",
        "     out=point_sample(f,n_points)\n",
        "    out=normalise(out)\n",
        "    out=rotate(out)\n",
        "    out=add_noise(out)\n",
        "    samp={}\n",
        "    samp[\"pointcloud\"]=out\n",
        "    samp['category']=category\n",
        "    cloud.append(samp)\n",
        "    print(i)\n",
        "    \n",
        "  return cloud  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6hdWGtKZsBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatr=data_creator(path,1024,\"train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLkpTqriLPaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatr=np.array(datatr)\n",
        "#x,y,z=data[0]['pointcloud']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlEy7jYLJK9s",
        "colab_type": "code",
        "outputId": "0467fbd4-b17c-46a5-f325-0d296692d18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "inv_classes = {i: cat for cat, i in classes.items()};\n",
        "inv_classes"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'bathtub',\n",
              " 1: 'bed',\n",
              " 2: 'chair',\n",
              " 3: 'desk',\n",
              " 4: 'dresser',\n",
              " 5: 'monitor',\n",
              " 6: 'night_stand',\n",
              " 7: 'sofa',\n",
              " 8: 'table',\n",
              " 9: 'toilet'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H00Ef1c09F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds=[]\n",
        "for i in range(len(datatr)):\n",
        "  x,y,z=datatr[i]['pointcloud']\n",
        "  label=datatr[i]['category']\n",
        "  label=classes[label]\n",
        "  arr=np.array([x,y,z])\n",
        "  arr=torch.from_numpy(arr)\n",
        "  sam={}\n",
        "  sam['pc']=arr\n",
        "  sam['lab']=label\n",
        "  ds.append(sam)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=ds, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdCV-bidJzID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test=data_creator(path,1024,\"test\")\n",
        "data_test=np.array(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybxi71UHJtp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_test=[]\n",
        "for i in range(len(data_test)):\n",
        "  x,y,z=data_test[i]['pointcloud']\n",
        "  label=data_test[i]['category']\n",
        "  label=classes[label]\n",
        "  arr=np.array([x,y,z])\n",
        "  arr=torch.from_numpy(arr)\n",
        "  sam={}\n",
        "  sam['pc']=arr\n",
        "  sam['lab']=label\n",
        "  ds_test.append(sam)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DataLoader(dataset=ds_test, batch_size=32,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZX1oFpjdBdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22b7e394-f30c-460a-cf42-299b6acff423"
      },
      "source": [
        "real_batch = next(iter(test_loader))\n",
        "labe=real_batch['lab']\n",
        "print(labe.size(0))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndqvWgWmQPlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class STransform(nn.Module):\n",
        "  def __init__(self,n_points):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv1d(3,64,1)\n",
        "    self.bn1=nn.BatchNorm1d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.conv2=nn.Conv1d(64,128,1)\n",
        "    self.bn2=nn.BatchNorm1d(128)\n",
        "    self.conv3=nn.Conv1d(128,1024,1)\n",
        "    self.bn3=nn.BatchNorm1d(1024)\n",
        "    self.maxpool=nn.MaxPool1d(1024)\n",
        "    self.fc1=nn.Linear(1024,512)\n",
        "    self.bn4=nn.BatchNorm1d(512)\n",
        "    self.fc2=nn.Linear(512,256)\n",
        "    self.bn5=nn.BatchNorm1d(256)\n",
        "    self.fc3=nn.Linear(256,9)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    #b*3*1024\n",
        "    bs=x.size(0)\n",
        "    out=self.relu(self.bn1(self.conv1(x)))\n",
        "    out=self.relu(self.bn2(self.conv2(out)))\n",
        "    out=self.relu(self.bn3(self.conv3(out)))\n",
        "    out=self.maxpool(out)\n",
        "    #b*1024*1\n",
        "    out=out.view(-1,1024)\n",
        "    out=self.relu(self.bn4(self.fc1(out)))\n",
        "    out=self.relu(self.bn5(self.fc2(out)))\n",
        "    out=self.fc3(out)\n",
        "    out=out.view(-1,3,3)\n",
        "    init = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
        "    out=out+init.cuda()\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvE-LIV9aR8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FTransform(nn.Module):\n",
        "  def __init__(self,n_points):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv1d(64,64,1)\n",
        "    self.bn1=nn.BatchNorm1d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.conv2=nn.Conv1d(64,128,1)\n",
        "    self.bn2=nn.BatchNorm1d(128)\n",
        "    self.conv3=nn.Conv1d(128,1024,1)\n",
        "    self.bn3=nn.BatchNorm1d(1024)\n",
        "    self.maxpool=nn.MaxPool1d(1024)\n",
        "    self.fc1=nn.Linear(1024,512)\n",
        "    self.bn4=nn.BatchNorm1d(512)\n",
        "    self.fc2=nn.Linear(512,256)\n",
        "    self.bn5=nn.BatchNorm1d(256)\n",
        "    self.fc3=nn.Linear(256,4096)\n",
        "\n",
        "  def forward(self,x):\n",
        "    #b*3*1024\n",
        "    bs=x.size(0)\n",
        "    out=self.relu(self.bn1(self.conv1(x)))\n",
        "    out=self.relu(self.bn2(self.conv2(out)))\n",
        "    out=self.relu(self.bn3(self.conv3(out)))\n",
        "    out=self.maxpool(out)\n",
        "    #b*1024*1\n",
        "    out=out.view(-1,1024)\n",
        "    out=self.relu(self.bn4(self.fc1(out)))\n",
        "    out=self.relu(self.bn5(self.fc2(out)))\n",
        "    out=self.fc3(out)\n",
        "    out=out.view(-1,64,64)\n",
        "    init = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
        "    out=out+init.cuda()\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuDlsvggjuYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,n_points):\n",
        "    super().__init__()\n",
        "    self.n_points=n_points\n",
        "    self.trans3=STransform(self.n_points).to(device)\n",
        "    self.trans64=FTransform(self.n_points).to (device)\n",
        "    self.conv1=nn.Conv1d(3,64,1)\n",
        "    self.bn1=nn.BatchNorm1d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.conv2=nn.Conv1d(64,64,1)\n",
        "    self.bn2=nn.BatchNorm1d(64)\n",
        "    self.conv3=nn.Conv1d(64,64,1)\n",
        "    self.bn3=nn.BatchNorm1d(64)\n",
        "    self.conv4=nn.Conv1d(64,128,1)\n",
        "    self.bn4=nn.BatchNorm1d(128)\n",
        "    self.conv5=nn.Conv1d(128,1024,1)\n",
        "    self.bn5=nn.BatchNorm1d(1024)\n",
        "    self.maxpool=nn.MaxPool1d(1024)\n",
        "    self.fc1=nn.Linear(1024,512)\n",
        "    self.bn6=nn.BatchNorm1d(512)\n",
        "    self.fc2=nn.Linear(512,256)\n",
        "    self.bn7=nn.BatchNorm1d(256)\n",
        "    self.drop=nn.Dropout(0.3)\n",
        "    self.fc3=nn.Linear(256,10)\n",
        "    self.softmax=nn.Softmax(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    ST=self.trans3(x)\n",
        "    out=torch.bmm(torch.transpose(x,1,2),ST)\n",
        "    out=out.view(-1,3,1024)\n",
        "    out=self.relu(self.bn1(self.conv1(out)))\n",
        "    out=self.relu(self.bn2(self.conv2(out)))\n",
        "    FT=self.trans64(out)\n",
        "    out=torch.bmm(torch.transpose(out,1,2),FT)\n",
        "    out=out.view(-1,64,1024)\n",
        "    out=self.relu(self.bn3(self.conv3(out)))\n",
        "    out=self.relu(self.bn4(self.conv4(out)))\n",
        "    out=self.relu(self.bn5(self.conv5(out)))\n",
        "    out=self.maxpool(out)\n",
        "    out=out.view(-1,1024)\n",
        "    out=self.relu(self.bn6(self.fc1(out)))\n",
        "    out=self.relu(self.bn7(self.drop(self.fc2(out))))\n",
        "    out=self.fc3(out)\n",
        "\n",
        "    return out,FT\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhP7hsgakT6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94MRrsVwCyZn",
        "colab_type": "code",
        "outputId": "69762973-629f-42ee-aaa6-da5bfac79469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(model,(3,1024),batch_size=32)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1             [32, 64, 1024]             256\n",
            "       BatchNorm1d-2             [32, 64, 1024]             128\n",
            "              ReLU-3             [32, 64, 1024]               0\n",
            "            Conv1d-4            [32, 128, 1024]           8,320\n",
            "       BatchNorm1d-5            [32, 128, 1024]             256\n",
            "              ReLU-6            [32, 128, 1024]               0\n",
            "            Conv1d-7           [32, 1024, 1024]         132,096\n",
            "       BatchNorm1d-8           [32, 1024, 1024]           2,048\n",
            "              ReLU-9           [32, 1024, 1024]               0\n",
            "        MaxPool1d-10              [32, 1024, 1]               0\n",
            "           Linear-11                  [32, 512]         524,800\n",
            "      BatchNorm1d-12                  [32, 512]           1,024\n",
            "             ReLU-13                  [32, 512]               0\n",
            "           Linear-14                  [32, 256]         131,328\n",
            "      BatchNorm1d-15                  [32, 256]             512\n",
            "             ReLU-16                  [32, 256]               0\n",
            "           Linear-17                    [32, 9]           2,313\n",
            "       STransform-18                 [32, 3, 3]               0\n",
            "           Conv1d-19             [32, 64, 1024]             256\n",
            "      BatchNorm1d-20             [32, 64, 1024]             128\n",
            "             ReLU-21             [32, 64, 1024]               0\n",
            "           Conv1d-22             [32, 64, 1024]           4,160\n",
            "      BatchNorm1d-23             [32, 64, 1024]             128\n",
            "             ReLU-24             [32, 64, 1024]               0\n",
            "           Conv1d-25             [32, 64, 1024]           4,160\n",
            "      BatchNorm1d-26             [32, 64, 1024]             128\n",
            "             ReLU-27             [32, 64, 1024]               0\n",
            "           Conv1d-28            [32, 128, 1024]           8,320\n",
            "      BatchNorm1d-29            [32, 128, 1024]             256\n",
            "             ReLU-30            [32, 128, 1024]               0\n",
            "           Conv1d-31           [32, 1024, 1024]         132,096\n",
            "      BatchNorm1d-32           [32, 1024, 1024]           2,048\n",
            "             ReLU-33           [32, 1024, 1024]               0\n",
            "        MaxPool1d-34              [32, 1024, 1]               0\n",
            "           Linear-35                  [32, 512]         524,800\n",
            "      BatchNorm1d-36                  [32, 512]           1,024\n",
            "             ReLU-37                  [32, 512]               0\n",
            "           Linear-38                  [32, 256]         131,328\n",
            "      BatchNorm1d-39                  [32, 256]             512\n",
            "             ReLU-40                  [32, 256]               0\n",
            "           Linear-41                 [32, 4096]       1,052,672\n",
            "       FTransform-42               [32, 64, 64]               0\n",
            "           Conv1d-43             [32, 64, 1024]           4,160\n",
            "      BatchNorm1d-44             [32, 64, 1024]             128\n",
            "             ReLU-45             [32, 64, 1024]               0\n",
            "           Conv1d-46            [32, 128, 1024]           8,320\n",
            "      BatchNorm1d-47            [32, 128, 1024]             256\n",
            "             ReLU-48            [32, 128, 1024]               0\n",
            "           Conv1d-49           [32, 1024, 1024]         132,096\n",
            "      BatchNorm1d-50           [32, 1024, 1024]           2,048\n",
            "             ReLU-51           [32, 1024, 1024]               0\n",
            "        MaxPool1d-52              [32, 1024, 1]               0\n",
            "           Linear-53                  [32, 512]         524,800\n",
            "      BatchNorm1d-54                  [32, 512]           1,024\n",
            "             ReLU-55                  [32, 512]               0\n",
            "           Linear-56                  [32, 256]         131,328\n",
            "          Dropout-57                  [32, 256]               0\n",
            "      BatchNorm1d-58                  [32, 256]             512\n",
            "             ReLU-59                  [32, 256]               0\n",
            "           Linear-60                   [32, 10]           2,570\n",
            "================================================================\n",
            "Total params: 3,472,339\n",
            "Trainable params: 3,472,339\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 2836.51\n",
            "Params size (MB): 13.25\n",
            "Estimated Total Size (MB): 2850.13\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NVSzgsYC-h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(out,label,mat64,bs):\n",
        "  criterion=nn.CrossEntropyLoss().to(device)\n",
        "  id=torch.eye(64, requires_grad=True).repeat(bs,1,1).to(device)\n",
        "  reg=id-torch.bmm(mat64,torch.transpose(mat64,1,2)).to(device)\n",
        "  los=criterion(out,label)+0.001*torch.norm(reg)/float(bs)\n",
        "  #los=criterion(out,label)\n",
        "  return los"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_lrOxoLCTjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=100\n",
        "lr=0.001\n",
        "model=Net(1024).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKGAvDlUDmLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5468b1ba-df9c-4c61-e6f0-d9c430d2cddc"
      },
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        points,label=data['pc'].to(device).float(),data['lab'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out,mat64=model(points)\n",
        "        \n",
        "        bs=out.size(0)\n",
        "        losse=loss(out,label,mat64,bs)\n",
        "        \n",
        "        losse.backward()\n",
        "        optimizer.step()\n",
        "        if (i+1) % 25 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1,epochs, i+1, total_step, losse.item()))  \n",
        "    if (epoch+1)%20==0:\n",
        "        lr=lr/2.0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for datate in test_loader:\n",
        "          points,label=datate['pc'].to(device).float(),datate['lab'].to(device)\n",
        "          outputs,_ = model(points)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += label.size(0)\n",
        "          correct += (predicted == label).sum().item()\n",
        "\n",
        "        print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))   \n",
        "       "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Step [25/125] Loss: 0.0352\n",
            "Epoch [1/100], Step [50/125] Loss: 0.1999\n",
            "Epoch [1/100], Step [75/125] Loss: 0.0050\n",
            "Epoch [1/100], Step [100/125] Loss: 0.0707\n",
            "Epoch [1/100], Step [125/125] Loss: 0.0079\n",
            "Accuracy of the model on the test images: 64.09691629955947 %\n",
            "Epoch [2/100], Step [25/125] Loss: 0.0047\n",
            "Epoch [2/100], Step [50/125] Loss: 0.0846\n",
            "Epoch [2/100], Step [75/125] Loss: 0.1666\n",
            "Epoch [2/100], Step [100/125] Loss: 0.0038\n",
            "Epoch [2/100], Step [125/125] Loss: 0.0156\n",
            "Accuracy of the model on the test images: 61.23348017621145 %\n",
            "Epoch [3/100], Step [25/125] Loss: 0.0306\n",
            "Epoch [3/100], Step [50/125] Loss: 0.0387\n",
            "Epoch [3/100], Step [75/125] Loss: 0.0632\n",
            "Epoch [3/100], Step [100/125] Loss: 0.0207\n",
            "Epoch [3/100], Step [125/125] Loss: 0.0105\n",
            "Accuracy of the model on the test images: 59.030837004405285 %\n",
            "Epoch [4/100], Step [25/125] Loss: 0.3694\n",
            "Epoch [4/100], Step [50/125] Loss: 0.1019\n",
            "Epoch [4/100], Step [75/125] Loss: 0.0926\n",
            "Epoch [4/100], Step [100/125] Loss: 0.0996\n",
            "Epoch [4/100], Step [125/125] Loss: 0.0327\n",
            "Accuracy of the model on the test images: 62.00440528634361 %\n",
            "Epoch [5/100], Step [25/125] Loss: 0.0108\n",
            "Epoch [5/100], Step [50/125] Loss: 0.0396\n",
            "Epoch [5/100], Step [75/125] Loss: 0.0202\n",
            "Epoch [5/100], Step [100/125] Loss: 0.1215\n",
            "Epoch [5/100], Step [125/125] Loss: 0.0179\n",
            "Accuracy of the model on the test images: 60.02202643171806 %\n",
            "Epoch [6/100], Step [25/125] Loss: 0.0050\n",
            "Epoch [6/100], Step [50/125] Loss: 0.0045\n",
            "Epoch [6/100], Step [75/125] Loss: 0.0202\n",
            "Epoch [6/100], Step [100/125] Loss: 0.0030\n",
            "Epoch [6/100], Step [125/125] Loss: 0.0044\n",
            "Accuracy of the model on the test images: 60.79295154185022 %\n",
            "Epoch [7/100], Step [25/125] Loss: 0.0058\n",
            "Epoch [7/100], Step [50/125] Loss: 0.0024\n",
            "Epoch [7/100], Step [75/125] Loss: 0.0021\n",
            "Epoch [7/100], Step [100/125] Loss: 0.0022\n",
            "Epoch [7/100], Step [125/125] Loss: 0.0023\n",
            "Accuracy of the model on the test images: 63.32599118942731 %\n",
            "Epoch [8/100], Step [25/125] Loss: 0.0021\n",
            "Epoch [8/100], Step [50/125] Loss: 0.0018\n",
            "Epoch [8/100], Step [75/125] Loss: 0.0015\n",
            "Epoch [8/100], Step [100/125] Loss: 0.0016\n",
            "Epoch [8/100], Step [125/125] Loss: 0.0018\n",
            "Accuracy of the model on the test images: 62.88546255506608 %\n",
            "Epoch [9/100], Step [25/125] Loss: 0.0014\n",
            "Epoch [9/100], Step [50/125] Loss: 0.0017\n",
            "Epoch [9/100], Step [75/125] Loss: 0.0012\n",
            "Epoch [9/100], Step [100/125] Loss: 0.0014\n",
            "Epoch [9/100], Step [125/125] Loss: 0.0015\n",
            "Accuracy of the model on the test images: 63.1057268722467 %\n",
            "Epoch [10/100], Step [25/125] Loss: 0.0011\n",
            "Epoch [10/100], Step [50/125] Loss: 0.0011\n",
            "Epoch [10/100], Step [75/125] Loss: 0.0012\n",
            "Epoch [10/100], Step [100/125] Loss: 0.0015\n",
            "Epoch [10/100], Step [125/125] Loss: 0.0013\n",
            "Accuracy of the model on the test images: 63.32599118942731 %\n",
            "Epoch [11/100], Step [25/125] Loss: 0.0009\n",
            "Epoch [11/100], Step [50/125] Loss: 0.0019\n",
            "Epoch [11/100], Step [75/125] Loss: 0.0083\n",
            "Epoch [11/100], Step [100/125] Loss: 0.0011\n",
            "Epoch [11/100], Step [125/125] Loss: 0.0036\n",
            "Accuracy of the model on the test images: 62.44493392070485 %\n",
            "Epoch [12/100], Step [25/125] Loss: 0.0015\n",
            "Epoch [12/100], Step [50/125] Loss: 0.0027\n",
            "Epoch [12/100], Step [75/125] Loss: 0.0657\n",
            "Epoch [12/100], Step [100/125] Loss: 0.0345\n",
            "Epoch [12/100], Step [125/125] Loss: 0.5064\n",
            "Accuracy of the model on the test images: 54.18502202643172 %\n",
            "Epoch [13/100], Step [25/125] Loss: 0.2832\n",
            "Epoch [13/100], Step [50/125] Loss: 0.0211\n",
            "Epoch [13/100], Step [75/125] Loss: 0.0279\n",
            "Epoch [13/100], Step [100/125] Loss: 0.0593\n",
            "Epoch [13/100], Step [125/125] Loss: 0.1378\n",
            "Accuracy of the model on the test images: 63.986784140969164 %\n",
            "Epoch [14/100], Step [25/125] Loss: 0.0085\n",
            "Epoch [14/100], Step [50/125] Loss: 0.3423\n",
            "Epoch [14/100], Step [75/125] Loss: 0.0223\n",
            "Epoch [14/100], Step [100/125] Loss: 0.0659\n",
            "Epoch [14/100], Step [125/125] Loss: 0.0063\n",
            "Accuracy of the model on the test images: 61.013215859030836 %\n",
            "Epoch [15/100], Step [25/125] Loss: 0.0393\n",
            "Epoch [15/100], Step [50/125] Loss: 0.0037\n",
            "Epoch [15/100], Step [75/125] Loss: 0.1562\n",
            "Epoch [15/100], Step [100/125] Loss: 0.0573\n",
            "Epoch [15/100], Step [125/125] Loss: 0.0387\n",
            "Accuracy of the model on the test images: 60.903083700440526 %\n",
            "Epoch [16/100], Step [25/125] Loss: 0.2556\n",
            "Epoch [16/100], Step [50/125] Loss: 0.1163\n",
            "Epoch [16/100], Step [75/125] Loss: 0.1911\n",
            "Epoch [16/100], Step [100/125] Loss: 0.0880\n",
            "Epoch [16/100], Step [125/125] Loss: 0.0178\n",
            "Accuracy of the model on the test images: 62.99559471365639 %\n",
            "Epoch [17/100], Step [25/125] Loss: 0.0102\n",
            "Epoch [17/100], Step [50/125] Loss: 0.0045\n",
            "Epoch [17/100], Step [75/125] Loss: 0.0062\n",
            "Epoch [17/100], Step [100/125] Loss: 0.0046\n",
            "Epoch [17/100], Step [125/125] Loss: 0.0079\n",
            "Accuracy of the model on the test images: 65.85903083700441 %\n",
            "Epoch [18/100], Step [25/125] Loss: 0.0179\n",
            "Epoch [18/100], Step [50/125] Loss: 0.0030\n",
            "Epoch [18/100], Step [75/125] Loss: 0.0178\n",
            "Epoch [18/100], Step [100/125] Loss: 0.3523\n",
            "Epoch [18/100], Step [125/125] Loss: 0.0099\n",
            "Accuracy of the model on the test images: 59.25110132158591 %\n",
            "Epoch [19/100], Step [25/125] Loss: 0.0107\n",
            "Epoch [19/100], Step [50/125] Loss: 0.0043\n",
            "Epoch [19/100], Step [75/125] Loss: 0.0093\n",
            "Epoch [19/100], Step [100/125] Loss: 0.0077\n",
            "Epoch [19/100], Step [125/125] Loss: 0.0026\n",
            "Accuracy of the model on the test images: 62.66519823788546 %\n",
            "Epoch [20/100], Step [25/125] Loss: 0.0400\n",
            "Epoch [20/100], Step [50/125] Loss: 0.0024\n",
            "Epoch [20/100], Step [75/125] Loss: 0.0026\n",
            "Epoch [20/100], Step [100/125] Loss: 0.0038\n",
            "Epoch [20/100], Step [125/125] Loss: 0.0024\n",
            "Accuracy of the model on the test images: 66.85022026431719 %\n",
            "Epoch [21/100], Step [25/125] Loss: 0.0050\n",
            "Epoch [21/100], Step [50/125] Loss: 0.0018\n",
            "Epoch [21/100], Step [75/125] Loss: 0.0014\n",
            "Epoch [21/100], Step [100/125] Loss: 0.0014\n",
            "Epoch [21/100], Step [125/125] Loss: 0.0018\n",
            "Accuracy of the model on the test images: 67.51101321585904 %\n",
            "Epoch [22/100], Step [25/125] Loss: 0.0014\n",
            "Epoch [22/100], Step [50/125] Loss: 0.0010\n",
            "Epoch [22/100], Step [75/125] Loss: 0.0016\n",
            "Epoch [22/100], Step [100/125] Loss: 0.0011\n",
            "Epoch [22/100], Step [125/125] Loss: 0.0013\n",
            "Accuracy of the model on the test images: 66.51982378854626 %\n",
            "Epoch [23/100], Step [25/125] Loss: 0.0012\n",
            "Epoch [23/100], Step [50/125] Loss: 0.0011\n",
            "Epoch [23/100], Step [75/125] Loss: 0.0010\n",
            "Epoch [23/100], Step [100/125] Loss: 0.0013\n",
            "Epoch [23/100], Step [125/125] Loss: 0.0010\n",
            "Accuracy of the model on the test images: 66.74008810572687 %\n",
            "Epoch [24/100], Step [25/125] Loss: 0.0010\n",
            "Epoch [24/100], Step [50/125] Loss: 0.0009\n",
            "Epoch [24/100], Step [75/125] Loss: 0.0009\n",
            "Epoch [24/100], Step [100/125] Loss: 0.0008\n",
            "Epoch [24/100], Step [125/125] Loss: 0.0010\n",
            "Accuracy of the model on the test images: 66.29955947136564 %\n",
            "Epoch [25/100], Step [25/125] Loss: 0.0010\n",
            "Epoch [25/100], Step [50/125] Loss: 0.0008\n",
            "Epoch [25/100], Step [75/125] Loss: 0.0008\n",
            "Epoch [25/100], Step [100/125] Loss: 0.0009\n",
            "Epoch [25/100], Step [125/125] Loss: 0.0012\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [26/100], Step [25/125] Loss: 0.0016\n",
            "Epoch [26/100], Step [50/125] Loss: 0.0025\n",
            "Epoch [26/100], Step [75/125] Loss: 0.0163\n",
            "Epoch [26/100], Step [100/125] Loss: 0.1905\n",
            "Epoch [26/100], Step [125/125] Loss: 0.2809\n",
            "Accuracy of the model on the test images: 54.07488986784141 %\n",
            "Epoch [27/100], Step [25/125] Loss: 0.0113\n",
            "Epoch [27/100], Step [50/125] Loss: 0.4603\n",
            "Epoch [27/100], Step [75/125] Loss: 0.7828\n",
            "Epoch [27/100], Step [100/125] Loss: 0.0341\n",
            "Epoch [27/100], Step [125/125] Loss: 0.0325\n",
            "Accuracy of the model on the test images: 61.784140969163 %\n",
            "Epoch [28/100], Step [25/125] Loss: 0.0305\n",
            "Epoch [28/100], Step [50/125] Loss: 0.1631\n",
            "Epoch [28/100], Step [75/125] Loss: 0.0357\n",
            "Epoch [28/100], Step [100/125] Loss: 0.0099\n",
            "Epoch [28/100], Step [125/125] Loss: 0.2107\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [29/100], Step [25/125] Loss: 0.0988\n",
            "Epoch [29/100], Step [50/125] Loss: 0.0084\n",
            "Epoch [29/100], Step [75/125] Loss: 0.0044\n",
            "Epoch [29/100], Step [100/125] Loss: 0.0385\n",
            "Epoch [29/100], Step [125/125] Loss: 0.0067\n",
            "Accuracy of the model on the test images: 60.903083700440526 %\n",
            "Epoch [30/100], Step [25/125] Loss: 0.0031\n",
            "Epoch [30/100], Step [50/125] Loss: 0.0042\n",
            "Epoch [30/100], Step [75/125] Loss: 0.0064\n",
            "Epoch [30/100], Step [100/125] Loss: 0.0044\n",
            "Epoch [30/100], Step [125/125] Loss: 0.0036\n",
            "Accuracy of the model on the test images: 64.97797356828194 %\n",
            "Epoch [31/100], Step [25/125] Loss: 0.0017\n",
            "Epoch [31/100], Step [50/125] Loss: 0.0021\n",
            "Epoch [31/100], Step [75/125] Loss: 0.0018\n",
            "Epoch [31/100], Step [100/125] Loss: 0.0012\n",
            "Epoch [31/100], Step [125/125] Loss: 0.0019\n",
            "Accuracy of the model on the test images: 64.75770925110132 %\n",
            "Epoch [32/100], Step [25/125] Loss: 0.0012\n",
            "Epoch [32/100], Step [50/125] Loss: 0.0012\n",
            "Epoch [32/100], Step [75/125] Loss: 0.0012\n",
            "Epoch [32/100], Step [100/125] Loss: 0.0011\n",
            "Epoch [32/100], Step [125/125] Loss: 0.0012\n",
            "Accuracy of the model on the test images: 65.52863436123349 %\n",
            "Epoch [33/100], Step [25/125] Loss: 0.0010\n",
            "Epoch [33/100], Step [50/125] Loss: 0.0009\n",
            "Epoch [33/100], Step [75/125] Loss: 0.0008\n",
            "Epoch [33/100], Step [100/125] Loss: 0.0008\n",
            "Epoch [33/100], Step [125/125] Loss: 0.0009\n",
            "Accuracy of the model on the test images: 65.19823788546256 %\n",
            "Epoch [34/100], Step [25/125] Loss: 0.0008\n",
            "Epoch [34/100], Step [50/125] Loss: 0.0008\n",
            "Epoch [34/100], Step [75/125] Loss: 0.0007\n",
            "Epoch [34/100], Step [100/125] Loss: 0.0007\n",
            "Epoch [34/100], Step [125/125] Loss: 0.0010\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [35/100], Step [25/125] Loss: 0.0008\n",
            "Epoch [35/100], Step [50/125] Loss: 0.0007\n",
            "Epoch [35/100], Step [75/125] Loss: 0.0006\n",
            "Epoch [35/100], Step [100/125] Loss: 0.0007\n",
            "Epoch [35/100], Step [125/125] Loss: 0.0006\n",
            "Accuracy of the model on the test images: 64.09691629955947 %\n",
            "Epoch [36/100], Step [25/125] Loss: 0.0006\n",
            "Epoch [36/100], Step [50/125] Loss: 0.0006\n",
            "Epoch [36/100], Step [75/125] Loss: 0.0006\n",
            "Epoch [36/100], Step [100/125] Loss: 0.0005\n",
            "Epoch [36/100], Step [125/125] Loss: 0.0006\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [37/100], Step [25/125] Loss: 0.0007\n",
            "Epoch [37/100], Step [50/125] Loss: 0.0008\n",
            "Epoch [37/100], Step [75/125] Loss: 0.0004\n",
            "Epoch [37/100], Step [100/125] Loss: 0.0005\n",
            "Epoch [37/100], Step [125/125] Loss: 0.0006\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [38/100], Step [25/125] Loss: 0.0006\n",
            "Epoch [38/100], Step [50/125] Loss: 0.0004\n",
            "Epoch [38/100], Step [75/125] Loss: 0.0004\n",
            "Epoch [38/100], Step [100/125] Loss: 0.0005\n",
            "Epoch [38/100], Step [125/125] Loss: 0.0004\n",
            "Accuracy of the model on the test images: 65.63876651982379 %\n",
            "Epoch [39/100], Step [25/125] Loss: 0.0004\n",
            "Epoch [39/100], Step [50/125] Loss: 0.0004\n",
            "Epoch [39/100], Step [75/125] Loss: 0.0004\n",
            "Epoch [39/100], Step [100/125] Loss: 0.0004\n",
            "Epoch [39/100], Step [125/125] Loss: 0.0005\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [40/100], Step [25/125] Loss: 0.0004\n",
            "Epoch [40/100], Step [50/125] Loss: 0.0004\n",
            "Epoch [40/100], Step [75/125] Loss: 0.0004\n",
            "Epoch [40/100], Step [100/125] Loss: 0.0003\n",
            "Epoch [40/100], Step [125/125] Loss: 0.0005\n",
            "Accuracy of the model on the test images: 64.97797356828194 %\n",
            "Epoch [41/100], Step [25/125] Loss: 0.0003\n",
            "Epoch [41/100], Step [50/125] Loss: 0.0003\n",
            "Epoch [41/100], Step [75/125] Loss: 0.0003\n",
            "Epoch [41/100], Step [100/125] Loss: 0.0003\n",
            "Epoch [41/100], Step [125/125] Loss: 0.0005\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [42/100], Step [25/125] Loss: 0.0003\n",
            "Epoch [42/100], Step [50/125] Loss: 0.0003\n",
            "Epoch [42/100], Step [75/125] Loss: 0.0003\n",
            "Epoch [42/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [42/100], Step [125/125] Loss: 0.0003\n",
            "Accuracy of the model on the test images: 65.30837004405286 %\n",
            "Epoch [43/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [43/100], Step [50/125] Loss: 0.0003\n",
            "Epoch [43/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [43/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [43/100], Step [125/125] Loss: 0.0003\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [44/100], Step [25/125] Loss: 0.0003\n",
            "Epoch [44/100], Step [50/125] Loss: 0.0003\n",
            "Epoch [44/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [44/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [44/100], Step [125/125] Loss: 0.0003\n",
            "Accuracy of the model on the test images: 64.64757709251101 %\n",
            "Epoch [45/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [45/100], Step [50/125] Loss: 0.0002\n",
            "Epoch [45/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [45/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [45/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.63876651982379 %\n",
            "Epoch [46/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [46/100], Step [50/125] Loss: 0.0002\n",
            "Epoch [46/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [46/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [46/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.63876651982379 %\n",
            "Epoch [47/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [47/100], Step [50/125] Loss: 0.0002\n",
            "Epoch [47/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [47/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [47/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.41850220264317 %\n",
            "Epoch [48/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [48/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [48/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [48/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [48/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 64.64757709251101 %\n",
            "Epoch [49/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [49/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [49/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [49/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [49/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.63876651982379 %\n",
            "Epoch [50/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [50/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [50/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [50/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [50/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.30837004405286 %\n",
            "Epoch [51/100], Step [25/125] Loss: 0.0002\n",
            "Epoch [51/100], Step [50/125] Loss: 0.0002\n",
            "Epoch [51/100], Step [75/125] Loss: 0.0002\n",
            "Epoch [51/100], Step [100/125] Loss: 0.0002\n",
            "Epoch [51/100], Step [125/125] Loss: 0.0002\n",
            "Accuracy of the model on the test images: 65.30837004405286 %\n",
            "Epoch [52/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [52/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [52/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [52/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [52/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.97797356828194 %\n",
            "Epoch [53/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [53/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [53/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [53/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [53/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 65.63876651982379 %\n",
            "Epoch [54/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [54/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [54/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [54/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [54/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 65.52863436123349 %\n",
            "Epoch [55/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [55/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [55/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [55/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [55/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.97797356828194 %\n",
            "Epoch [56/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [56/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [56/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [56/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [56/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [57/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [57/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [57/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [57/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [57/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 65.30837004405286 %\n",
            "Epoch [58/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [58/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [58/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [58/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [58/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [59/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [59/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [59/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [59/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [59/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.53744493392071 %\n",
            "Epoch [60/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [60/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [60/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [60/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [60/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.42731277533039 %\n",
            "Epoch [61/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [61/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [61/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [61/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [61/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.64757709251101 %\n",
            "Epoch [62/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [62/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [62/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [62/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [62/100], Step [125/125] Loss: 0.0001\n",
            "Accuracy of the model on the test images: 64.64757709251101 %\n",
            "Epoch [63/100], Step [25/125] Loss: 0.0001\n",
            "Epoch [63/100], Step [50/125] Loss: 0.0001\n",
            "Epoch [63/100], Step [75/125] Loss: 0.0001\n",
            "Epoch [63/100], Step [100/125] Loss: 0.0001\n",
            "Epoch [63/100], Step [125/125] Loss: 1.0500\n",
            "Accuracy of the model on the test images: 54.18502202643172 %\n",
            "Epoch [64/100], Step [25/125] Loss: 1.1623\n",
            "Epoch [64/100], Step [50/125] Loss: 0.5106\n",
            "Epoch [64/100], Step [75/125] Loss: 0.6690\n",
            "Epoch [64/100], Step [100/125] Loss: 0.2433\n",
            "Epoch [64/100], Step [125/125] Loss: 0.5098\n",
            "Accuracy of the model on the test images: 61.784140969163 %\n",
            "Epoch [65/100], Step [25/125] Loss: 0.0925\n",
            "Epoch [65/100], Step [50/125] Loss: 0.0130\n",
            "Epoch [65/100], Step [75/125] Loss: 0.0750\n",
            "Epoch [65/100], Step [100/125] Loss: 0.1530\n",
            "Epoch [65/100], Step [125/125] Loss: 0.1211\n",
            "Accuracy of the model on the test images: 60.68281938325991 %\n",
            "Epoch [66/100], Step [25/125] Loss: 0.0265\n",
            "Epoch [66/100], Step [50/125] Loss: 0.0205\n",
            "Epoch [66/100], Step [75/125] Loss: 0.0773\n",
            "Epoch [66/100], Step [100/125] Loss: 0.0157\n",
            "Epoch [66/100], Step [125/125] Loss: 0.0545\n",
            "Accuracy of the model on the test images: 63.65638766519824 %\n",
            "Epoch [67/100], Step [25/125] Loss: 0.0581\n",
            "Epoch [67/100], Step [50/125] Loss: 0.0051\n",
            "Epoch [67/100], Step [75/125] Loss: 0.0027\n",
            "Epoch [67/100], Step [100/125] Loss: 0.0058\n",
            "Epoch [67/100], Step [125/125] Loss: 0.0081\n",
            "Accuracy of the model on the test images: 62.22466960352423 %\n",
            "Epoch [68/100], Step [25/125] Loss: 0.0597\n",
            "Epoch [68/100], Step [50/125] Loss: 0.0073\n",
            "Epoch [68/100], Step [75/125] Loss: 0.0389\n",
            "Epoch [68/100], Step [100/125] Loss: 0.0084\n",
            "Epoch [68/100], Step [125/125] Loss: 0.0024\n",
            "Accuracy of the model on the test images: 62.44493392070485 %\n",
            "Epoch [69/100], Step [25/125] Loss: 0.0029\n",
            "Epoch [69/100], Step [50/125] Loss: 0.0076\n",
            "Epoch [69/100], Step [75/125] Loss: 0.0110\n",
            "Epoch [69/100], Step [100/125] Loss: 0.0475\n",
            "Epoch [69/100], Step [125/125] Loss: 0.1555\n",
            "Accuracy of the model on the test images: 58.25991189427313 %\n",
            "Epoch [70/100], Step [25/125] Loss: 0.0212\n",
            "Epoch [70/100], Step [50/125] Loss: 0.0060\n",
            "Epoch [70/100], Step [75/125] Loss: 0.0068\n",
            "Epoch [70/100], Step [100/125] Loss: 0.0050\n",
            "Epoch [70/100], Step [125/125] Loss: 0.0068\n",
            "Accuracy of the model on the test images: 62.77533039647577 %\n",
            "Epoch [71/100], Step [25/125] Loss: 0.5470\n",
            "Epoch [71/100], Step [50/125] Loss: 0.0582\n",
            "Epoch [71/100], Step [75/125] Loss: 0.0287\n",
            "Epoch [71/100], Step [100/125] Loss: 0.0041\n",
            "Epoch [71/100], Step [125/125] Loss: 0.0271\n",
            "Accuracy of the model on the test images: 66.51982378854626 %\n",
            "Epoch [72/100], Step [25/125] Loss: 0.2045\n",
            "Epoch [72/100], Step [50/125] Loss: 0.0325\n",
            "Epoch [72/100], Step [75/125] Loss: 0.0029\n",
            "Epoch [72/100], Step [100/125] Loss: 0.0022\n",
            "Epoch [72/100], Step [125/125] Loss: 0.0583\n",
            "Accuracy of the model on the test images: 64.86784140969164 %\n",
            "Epoch [73/100], Step [25/125] Loss: 0.0082\n",
            "Epoch [73/100], Step [50/125] Loss: 0.0175\n",
            "Epoch [73/100], Step [75/125] Loss: 0.0012\n",
            "Epoch [73/100], Step [100/125] Loss: 0.0012\n",
            "Epoch [73/100], Step [125/125] Loss: 0.0018\n",
            "Accuracy of the model on the test images: 63.215859030837 %\n",
            "Epoch [74/100], Step [25/125] Loss: 0.0011\n",
            "Epoch [74/100], Step [50/125] Loss: 0.0023\n",
            "Epoch [74/100], Step [75/125] Loss: 0.0010\n",
            "Epoch [74/100], Step [100/125] Loss: 0.0011\n",
            "Epoch [74/100], Step [125/125] Loss: 0.0010\n",
            "Accuracy of the model on the test images: 63.215859030837 %\n",
            "Epoch [75/100], Step [25/125] Loss: 0.0010\n",
            "Epoch [75/100], Step [50/125] Loss: 0.0009\n",
            "Epoch [75/100], Step [75/125] Loss: 0.0008\n",
            "Epoch [75/100], Step [100/125] Loss: 0.0007\n",
            "Epoch [75/100], Step [125/125] Loss: 0.0010\n",
            "Accuracy of the model on the test images: 63.65638766519824 %\n",
            "Epoch [76/100], Step [25/125] Loss: 0.0007\n",
            "Epoch [76/100], Step [50/125] Loss: 0.0010\n",
            "Epoch [76/100], Step [75/125] Loss: 0.0008\n",
            "Epoch [76/100], Step [100/125] Loss: 0.0008\n",
            "Epoch [76/100], Step [125/125] Loss: 0.0007\n",
            "Accuracy of the model on the test images: 63.215859030837 %\n",
            "Epoch [77/100], Step [25/125] Loss: 0.0006\n",
            "Epoch [77/100], Step [50/125] Loss: 0.0007\n",
            "Epoch [77/100], Step [75/125] Loss: 0.0006\n",
            "Epoch [77/100], Step [100/125] Loss: 0.0006\n",
            "Epoch [77/100], Step [125/125] Loss: 0.0007\n",
            "Accuracy of the model on the test images: 62.44493392070485 %\n",
            "Epoch [78/100], Step [25/125] Loss: 0.0007\n",
            "Epoch [78/100], Step [50/125] Loss: 0.0006\n",
            "Epoch [78/100], Step [75/125] Loss: 0.0007\n",
            "Epoch [78/100], Step [100/125] Loss: 0.0006\n",
            "Epoch [78/100], Step [125/125] Loss: 0.0009\n",
            "Accuracy of the model on the test images: 62.55506607929515 %\n",
            "Epoch [79/100], Step [25/125] Loss: 0.0006\n",
            "Epoch [79/100], Step [50/125] Loss: 0.0007\n",
            "Epoch [79/100], Step [75/125] Loss: 0.0009\n",
            "Epoch [79/100], Step [100/125] Loss: 0.0007\n",
            "Epoch [79/100], Step [125/125] Loss: 0.0020\n",
            "Accuracy of the model on the test images: 61.784140969163 %\n",
            "Epoch [80/100], Step [25/125] Loss: 0.0742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-dd0162714919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlosse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlosse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbvUG5vJUUje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}